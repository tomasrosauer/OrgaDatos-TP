{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_TRAIN = 'data/training.csv'\n",
    "FILE_TEST = 'data/testing.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscar Features en la Descripcion\n",
    "\n",
    "\n",
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark_csv as pycsv\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "sc.addPyFile('/home/marto/Desktop/pyspark_csv.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "def removePunctuation(text):\n",
    "    \n",
    "    text=str(text).lower().strip(' ')\n",
    "    text=unicodedata.normalize('NFD', text).encode('ascii','ignore')\n",
    "    text=text.decode('utf-8')\n",
    "    text=re.sub(r'[^a-zA-Z0-9 ]', ' ', text)   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getColums(names):\n",
    "    df_index = dataframe.schema.names\n",
    "    index = {}\n",
    "    for name in names:\n",
    "        if name in df_index:\n",
    "            index[name] = df_index.index(name)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letrasANumero(word):\n",
    "    dic = {\n",
    "        'mono': '1','uno': '1',\n",
    "        'un': '1','dos': '2',\n",
    "        'tres': '3','cuatro': '4',\n",
    "        'cinco': '5','seis': '6',\n",
    "        'siete': '7','ocho': '8'\n",
    "    }\n",
    "    if word in dic:\n",
    "        return dic[word]\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordToNumber(word):\n",
    "    try:\n",
    "        n = (int(letrasANumero(word)))\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1\n",
    "Esta busqueda se encarga de buscar bigramas en donde la primera o segunda palabra sea la buscada, y la restante, un numero o una palabra que pueda ser traducida a numero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buscarCantidad(string, palabra_especial, words):\n",
    "    cantidad = 0\n",
    "    l = string.split()\n",
    "    for i in range(0,len(l)-1):\n",
    "        if palabra_especial:\n",
    "            if l[i] == palabra_especial[0] or l[i+1] == palabra_especial[0]:\n",
    "                return palabra_especial[1]\n",
    "        if l[i] in words:\n",
    "            n = wordToNumber(l[i+1])\n",
    "            if n and n > cantidad:\n",
    "                cantidad = n\n",
    "        if l[i+1] in words:\n",
    "            n = wordToNumber(l[i])\n",
    "            if n and n > cantidad:\n",
    "                cantidad = n\n",
    "    return cantidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2\n",
    "Mientras que esta busqueda simplemente cuenta la cantidad de apariciones que tienen las palabras relacionadas a cada key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buscarFeature(features, des):\n",
    "    d = {}\n",
    "    for key in features:\n",
    "        d[key] = 0\n",
    "        for word in features[key]:\n",
    "            if word in des:\n",
    "                d[key] += 1    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguente funcion, busca cada uno de los valores del diccionario (mas abajo se explica y se muestra cual es) dentro de la descripcion. Existen dos tipos de busqueda distintas, (2) la busqueda de features, y (1) la busqueda de cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def busqueda(des):\n",
    "    ambientes = buscarCantidad(des,('monoambiente',1), ['ambiente','ambientes'])\n",
    "    cuartos = buscarCantidad(des,False, features['cuarto'])\n",
    "    banos = buscarCantidad(des,('banos',2), ['bano','banos'])\n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "    analyze = bigram_vectorizer.build_analyzer()\n",
    "    d = buscarFeature(features,analyze(des))\n",
    "    if d['bano'] > banos:\n",
    "        banos = d['bano']\n",
    "    d.pop('bano', None)\n",
    "    l = [ambientes,cuartos,banos] + list(d.values())\n",
    "    return tuple(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def juntar(x):\n",
    "    a = x[0][1]\n",
    "    a_d = x[1][1]\n",
    "    if (a == None) or (a > a_d):\n",
    "        return tuple([x[0][0]] + list(x[1]))\n",
    "    return tuple([x[0][0]] + list(x[1])[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diccionario de featues y sinonimos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguente diccionario es un diccionario de features y sinonimos, la idea de utilizar esta estructura para extraer datos de la descripcion es una solucion a los problemas obtenidos usando una lista de palabras y valores binarios para representar cada una, y luego The Hashing Trick, se logra tener el valor compacto de THT pero sin perder control sobre que es lo que buscamos y que es lo que obtenes. Tambien saber la cantidad de ciertas caracteristicas resulta util."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#diccionario de sinonimos\n",
    "features = {\n",
    "    'bano' : ['bano','banos','toilete'],\n",
    "    'cuarto' : ['cuarto', 'cuartos', 'habitacion', 'habitaciones', 'dormitorio', 'dormitorios'],\n",
    "    'cochera' : ['cochera','cocheras','estacionamiento','estacionamientos'],\n",
    "    'seguridad' : ['guardia', 'seguridad', 'garita'],\n",
    "    'gimnasio' : ['gym','gimnasio'],\n",
    "    'amenities' : ['spa','laundry','solarium',''],\n",
    "    'jardin' : ['parque','jardin','patio'],\n",
    "    'frio' : ['split','aire acondicionado'],\n",
    "    'calor' : ['caldera','losa radiante','radiadores','estufa','estufas','radiador'],\n",
    "    'portero' : ['encargado', 'portero', 'porteria'],\n",
    "    'pileta' : ['pileta', 'piscina'],\n",
    "    'terraza' : ['terraza'],\n",
    "    'balcon' : ['balcon','balcones'],\n",
    "    'tipos de ambientes' : ['comedor','cocina','living','lavadero','escritorio'],\n",
    "    'galeria' : ['galeria'],\n",
    "    'barrio privado': ['country','barrio privado','nordelta','barrio cerrado'],\n",
    "    'nuevo en venta' :['a estrenar','estrenar'],\n",
    "    'ubicacion' : ['esquina','avenida','centro','esquina','plaza','frente'],\n",
    "    'lujos': ['ceramicos','porcelanato','marmol','parquet','inoxidable','granito','aluminio','madera','club house'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training Dataser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plaintext_rdd = sc.textFile(FILE_TRAIN)\n",
    "dataframe = pycsv.csvToDataFrame(sqlContext, plaintext_rdd)\n",
    "data = dataframe.rdd\n",
    "columnas = ['id','description','rooms']\n",
    "idx = getColums(columnas)\n",
    "data = data.map(lambda x: (x[idx['id']], x[idx['rooms']], x[idx['description']]))\n",
    "data = data.map(lambda x: ((x[0],x[1]),removePunctuation(x[2])))\n",
    "data = data.map(lambda x: (x[0],busqueda(x[1])))\n",
    "data = data.map(juntar)\n",
    "columns = ['id', 'ambientes_des','cuartos'] + list(features.keys()) \n",
    "df = data.collect()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.DataFrame(df)\n",
    "df_train.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plaintext_rdd = sc.textFile(FILE_TEST)\n",
    "dataframe = pycsv.csvToDataFrame(sqlContext, plaintext_rdd)\n",
    "data = dataframe.rdd\n",
    "columnas = ['id','description','rooms']\n",
    "idx = getColums(columnas)\n",
    "data = data.map(lambda x: (x[idx['id']], x[idx['rooms']], x[idx['description']]))\n",
    "data = data.map(lambda x: ((x[0],x[1]),removePunctuation(x[2])))\n",
    "data = data.map(lambda x: (x[0],busqueda(x[1])))\n",
    "data = data.map(juntar)\n",
    "columns = ['id', 'ambientes_des','cuartos'] + list(features.keys()) \n",
    "df = data.collect()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_test = pd.DataFrame(df)\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras que todos los valores conseguidos por este metodo son nuevos, la busqueda de los ambientes en la descripcion no. Es por esto que se valida si los ambientes encontrados son mayores a los que la propiedad anticipaba con anterioridad o si estos eran nulos para remplazarlos. Los demas datos se agregan al dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateRooms(row):\n",
    "    a = np.isnan(row['rooms'])\n",
    "    b = np.isnan(row['ambientes_des'])\n",
    "    if a and not b:\n",
    "        return row['ambientes_des']\n",
    "    if (not a) and (not b):\n",
    "        return row['ambientes_des']\n",
    "    return row['rooms']\n",
    "\n",
    "def merge_rooms(df_complete, df_rooms, FILE_NAME):\n",
    "    FILE_NAME = FILE_NAME + \"-with-features.csv\"\n",
    "    df_rooms = df_rooms.set_index(['id'])\n",
    "    df_complete = df_complete.set_index(['id'])\n",
    "    \n",
    "    df = df_complete.join(df_rooms)\n",
    "    df['rooms'] = df.apply(lambda row: updateRooms(row), axis=1)\n",
    "    df = df.drop(df[['ambientes_des']], axis=1)\n",
    "    df.to_csv(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfT = pd.read_csv(FILE_TEST, low_memory=False)\n",
    "merge_rooms(dfT,df_test, 'data/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTR = pd.read_csv(FILE_TRAIN, low_memory=False)\n",
    "merge_rooms(dfTR,df_train, 'data/training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
